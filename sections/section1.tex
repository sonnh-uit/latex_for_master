\section{Tóm tắt}

Trong giai đoạn hiện nay, nhu cầu dữ liệu cho học máy cũng như các lĩnh vực khác liên tục tăng lên, do đó hệ thống lưu trữ chúng phải thích ứng với nhu cầu ngày càng tăng về hiệu suất, độ tin cậy và khả năng chịu lỗi. Điều này làm tăng độ phức tạp quản trị và chi phí. Cải thiện hiệu suất và tăng khả năng mở rộng của hệ thống trong khi vẫn duy trì chi phí thấp là rất quan trọng. Các giải pháp phần mềm lưu trữ được cho là hướng đi mới do giải pháp phần cứng vẫn quá đắt đỏ. 

Hadoop Distributes File System (HDFS) do  Apache Software Foundation phát triển đến nay đã có phiên bản thứ 3, là một giải pháp đáng tin cậy để lưu trữ và phân phối dữ liệu một cách đáng tin cậy trên nhiều node. Nghiên cứu này xem xét cách HDFS hoạt động trong thiết lập với các phần mềm hỗ trợ phân quyền và bảo mật khác như Kerberos, Openldap, Apache Ranger, YARN. Nghiên cứu thay đổi số lượng các node lưu trữ và tính toán để kiểm tra khả năng mở rộng của hệ thống. Nghiên cứu hướng đến việc thử nghiệm và kiểm tra tính chính xác các cam kết của HDFS, đồng thời phát hiện các điểm có tiềm năng cải tiến. Nghiên cứu này sẽ cải thiện hiểu biết về vệ thống HDFS cho cộng đồng, đồng thời thông qua các kịch bản được trình bày để giải quyết các hạn chế về hiệu suất của HDFS.